{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEURONS_COUNT = 10\n",
    "EPOCH = 100\n",
    "\n",
    "error = 0\n",
    "learning_speed = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train, label_train), (data_test, label_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.reshape(data_train.shape[0], data_train.shape[1] * data_train.shape[2]) / 255\n",
    "data_test = data_test.reshape(data_test.shape[0], data_test.shape[1] * data_test.shape[2]) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron:\n",
    "    _SIZE_OF_WEIGHTS = 784\n",
    "\n",
    "    def __init__(self, label: int):\n",
    "        self._weights = (np.random.rand(self._SIZE_OF_WEIGHTS) - 0.5) * 0.06\n",
    "        self._weights_correction = np.zeros(self._SIZE_OF_WEIGHTS)\n",
    "        self._bias = 1\n",
    "        self._label = label\n",
    "\n",
    "    def get_output_value(self, inputed_value):\n",
    "        return self._get_sigmoid(self._get_weighted_sum(inputed_value) + self._bias)\n",
    "    \n",
    "    def learn(self, inputed_value, inputed_label):\n",
    "        self._change_weights_correction(inputed_value)\n",
    "\n",
    "        if self._label != inputed_label:\n",
    "            if self.get_output_value(inputed_value) >= self._label:\n",
    "                self._weights += self._weights_correction\n",
    "            \n",
    "            return\n",
    "\n",
    "        if self.get_output_value(inputed_value) < self._label:\n",
    "            self._weights -= self._weights_correction\n",
    "            return\n",
    "            \n",
    "    def _get_sigmoid(self, weighted_sum):\n",
    "        return 1 / (1 + np.exp(-weighted_sum))\n",
    "    \n",
    "    def _get_sigmoid_diff(self, sigmoid):\n",
    "        return (1 + sigmoid) * (1 - sigmoid)\n",
    "\n",
    "    def _get_weighted_sum(self, inputed_value):\n",
    "        return np.sum(np.multiply(self._weights, inputed_value))\n",
    "    \n",
    "    def _get_learning_speed_coefficient(self, sigmoid, sigmoid_diff):\n",
    "        return -(self._label - sigmoid) * sigmoid_diff\n",
    "    \n",
    "    def _change_weights_correction(self,inputed_value):\n",
    "        sigmoid = self.get_output_value(inputed_value)\n",
    "        sigmoid_diff = self._get_sigmoid_diff(sigmoid)\n",
    "\n",
    "        self._weights_correction -= learning_speed * self._get_learning_speed_coefficient(sigmoid, sigmoid_diff) * inputed_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neurons(count: int):\n",
    "    return [neuron(i) for i in range(count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(output_value):\n",
    "    return np.sum([0.5 * (desired_value - output_value) * (desired_value - output_value) for desired_value in range(NEURONS_COUNT)])\n",
    "\n",
    "def change_error(output_value, neurons_count):\n",
    "    error += get_error(output_value) / neurons_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = get_neurons(NEURONS_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_count = len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6100\\1483186857.py:28: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-weighted_sum))\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for neuron in neurons:\n",
    "        for current_index in range(100):\n",
    "            neuron.learn(data_train[current_index], label_train[current_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6100\\1483186857.py:28: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-weighted_sum))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons[4].get_output_value(data_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
